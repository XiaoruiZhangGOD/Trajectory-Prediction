{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Project introduction\n",
    "# BEN, please write some introduction to the problem here.\n",
    "#      discuss some applications and our final goal (predicting motion)\n",
    "#      and show a picture or two describing the dataset (drone footage) or a diagram with our goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Importing\n",
    "We will be importing helper modules for processing the dataset and loading an LSTM trajectory tracker class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module import (add here as necessary)\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('./processing_scripts/')\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from simple_processing import load_simple_array, load_others_array\n",
    "from linear_error import compute_linear_error\n",
    "# import pandas as pd              <- these are used in the data processing step\n",
    "# import matplotlib.pylab as plt   <- \" ... \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Processing\n",
    "Load in the drone dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "#fname = './train_data/stanford/gates_5.txt'     # location of the datafile\n",
    "N_pixels = 20                                    # number of grid points per length in others array\n",
    "Nf = 10                                          # number of frames to observe before making prediction\n",
    "# Load the text file into the array formats\n",
    "#trajectories_simple, trajectories_others = process_text_file_csv(fname)\n",
    "#trajectories_simple = load_simple_array(fname)\n",
    "#trajectories_others = load_others_array(fname,N_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-031bd2bbe5d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_trajectories2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "train_trajectories1 = []\n",
    "train_trajectories2 = []\n",
    "for dirname in os.listdir('train_data'):\n",
    "    if dirname == 'stanford':\n",
    "        for filename in os.listdir('train_data/' + dirname):\n",
    "            if filename.endswith('.txt'):\n",
    "                trajectories = load_simple_array('train_data/' + dirname + '/' + filename)\n",
    "                train_trajectories1 += [traj[:10,:] for traj in trajectories]\n",
    "                train_trajectories2 += [traj[10:,:] for traj in trajectories]\n",
    "\n",
    "train_trajectories1 = np.stack(train_trajectories1)\n",
    "train_trajectories2 = np.stack(train_trajectories2)\n",
    "data_tensor = torch.Tensor(train_trajectories1)\n",
    "target_tensor = torch.Tensor(train_trajectories2)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(data_tensor, target_tensor)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size = 4)\n",
    "\n",
    "p = TrajectoryPredictor(2, 2, 4)\n",
    "p.train(train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute linear errors on both simple list and list containing others array\n",
    "linear_error_simple = compute_linear_error(trajectories_simple,Nf)\n",
    "linear_error_others = compute_linear_error(trajectories_others,Nf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
